#--------------------------------------------------------------------------------------------
# Wish list 

## THE BIG MIGRATION: 
#	- deal with any UNICODE strings anywhere.
# 	- use right mechanism for HTTP downloads. 
#	- geting page, streams and captions all have different types of download functions. Generalize!

## Reliable Download:
#	- create your own powerful downloader which can go chunk-by-chunk with better control. 
#	- get watch page to retrive the play duration - dont' need to downloard the full thing for it. 
#	- deal with network failures. -- retry, wait-n-resume
#	- deal with resume on socket. (resume partial downloads) 
#	- network reconnect should re-establish things [ start partial download from where it was left]
#	- parallel thread downloading 
#	- If youtube throws 404/403 - in actual downloads. it should not proceed like a normal flow. Exception should be handled. [ Done! ]
#	- Deal with signatured streams that otherwise throws 403 (e.g. '-RMD88DNaGk') 
#	- there exists custom urls for channels. see https://www.youtube.com/account_advanced
#	- my own channel is different from std (makemegenious) https://www.youtube.com/channel/UCzvGqEme9-yngxiYXY_Zk7A
#	- maintain partial download work for lists - 

# Page caching:
#	- cache every ytpage. it will solve many problems:
#	- if (large) extract fails and it is restarted, it shouldn't bring ALL pages which were once succesful! 
#	- once you do extract you have got all pages - now doing fetch on full channel/playlist OR part need not get_page() again.
# 	- if a particular video is part of multiple playlist or you try again without realizing, or somehow .yl is deleted 
# 	    caching will reduce hits going to youtube

## Trace and No repeat download:
#	- at the very minimal - if you try the same command again - whatever work has already been done, should not require redownload.
#	- maintain a trace and don't redownload what you have already got. { verify in the directory ... } 
# 	- skip what is already downloaded  { verify in the directory ... } 
#	- you can also check if the file is physically present. 
#	- downalod_stream function should provide data of actual status and details of download (put it to trace)
#	- MD5 or play duration verification of Media files (large ones) 
#	- needs to see that duration available locally matches with what is claimed by YT { to verify if the file downloaded is complete! } 
#	- where and how to keep the trace? what is the file format? 
#	- maintain csv generator that can keep the trace. 
#	- ask if the file to be downloaded already exists
`
## Generic Config and post processing:
#	- make config.py to access all configs (editable by users) which works as defaults 
#	- generic methods/ or customzable file titles. 
#	- generic policies in what to fetch : AudioOnly/VideoOnly/AV, Max res, 
#	- post processing of video. e.g. convert to mp3
#	- generalize the output file format ... make it what user wants. Can be done at FFMPEG level. 
#	- filters for download. From a given list - downloard only with specific Resolution, Playtime (skip 360p) 
#		- or downalod if title contains specific string. ( download Documentary.* in title - skip others) 
#	- default folder can be given in ytconfg.py  (or some yml file) 
#	- use varaible in default config as formatting items: e.g.
#	-   %H -> default_download_dir, %F -> current folder, %A -> Author/Channel name, %P -> playlist name, %T -> Title,
#	-   %R -> res %I -> id %S -> site name (youtube) %N -> sequence number (in list) 
#	- all configuration should be modifiable from commandline args also. 

## .yl file format and power fetch:
#	- now the .yl in turn can have references to full channel, playlist etc. expand all of them before download 
#	- when playlist URL is given instead of video in .yl file, recognise and trasnlate accordingly. 
#	- probe for file size during extract and capture it in yl format? 
#	- tabs being compulsory in .yl files is a problem, specially when the files are handwritten. 
#	- fetch can now be given multiple uid_references which it can download all serially
#	- download channels --by-playlist - so will keep each playlist in different subfolder 
#	- preserve COMMENTS in original .yl file if extracting again. 
# 	- by default making .yl to .yl again -> the tab limited fields can be erased. Everything written post # should be preserved. 
#		- this way repeated .yl to .yl will not add repeated columns, and also will not erease user notes. 
#	- create .yl (or equivalent) as a result of download of list 
#	-  meta attrib should download size of file / add in .yl 

## Beyond youtube:
#	- download from Dailymotion
#	- download from vimeo
#	- download from these sites including playlists/ channels. 

# Smart Downloads:	- OK these are huge - work but might as well WISH 
#	- collect all meta tags og:video:tag. 
#	- When you extract full channels, large playlists, use these tags to somehow cluster - make groups with comments.
#	- other form of grouping is, in a given channel - if parts of video are in playlist form make that a group. 
#	- similarly "N Grams" in title - "How stuff works - x", "How stuff works - y" etc. can be grouped. 

## General
#	- mkdir if folder for -f doesn't exist. 
#	- don't say 'Enjoy the video' when there is no download. 
#	- Resume incomplete downloads from where they were left 
#	- capture critical stuff and do clean exit when user presses Ctr+C 
#	- list control - follow list, pause, stop and resume post what is finished. 
#	- make it interactive shell? i.e. commands can be given while work is going on. Press Ctr+C to interrupt
#	- instead of pretty print. Video meta can be explained in more human readable format. 
#	- in case of multiple parallel downloads, the current \r funda won't work. So need central reporting engine.
# 	- file issues for well defined items. 
#	- prepare readme - specially for explaining usage and download_ref. 
#	- specify dependencies -e.g. certifi 
#	- if -o 'filename' supplied AFTER the URL_REF then it doesn't take 
#	- '/' is earased from title because it is not allowed in a file name. However it should be replace by some char not earased.
#	- default folder name is ./ But it can also be title of playlist or owner_name etc. for muliple videos
#	- we have v= vid= video= ,,,too many optinos to do same. so need to get rid of some options.
#	- save user/channel by playlist
#	- preserve comments (inline as well as full) in yl.
#	- make ytdownload or ytfetch and unify all apps.

#----------------------------------------------------------------------------------------------------
# Code TODO 
#	- make item logger global (how will you handle in multithread situation?) 
#	- centrlized all standard strings (including youtube.com/xxx where we are assuming known url 
#	- get rid of print_smap_XXX functions and no extra return value from parse_stream_map 
#	- keep all common strings in a central place 
#	- it's time, the code must have classes for important stuff. 
#	- load_list of different type should come with simple and single abstraction. 
#	- use of many 'prints' is not clean - convert it to log functions 
#	- make all stuff as classes.
#	- vmeta is very clumsy = it has two layers v[xxx] attribs and v[vmeta][xxx] attribs with quite an overlap. clean this.
#	- finally logging is no loger need to be as dense as it was required and logging as we do might be unclean for external users. fix
#-----------------------------------------------------------------------------------------------------

